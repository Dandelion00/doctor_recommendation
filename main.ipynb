{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcd2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic_settings in c:\\users\\sherl\\anaconda3\\lib\\site-packages (2.6.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: langchain in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.3.72)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\sherl\\anaconda3\\lib\\site-packages (2.1.8)\n",
      "Requirement already satisfied: langchain-qdrant in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: fastembed in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.7.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: qdrant-client in c:\\users\\sherl\\anaconda3\\lib\\site-packages (1.15.0)\n",
      "Requirement already satisfied: langgraph in c:\\users\\sherl\\anaconda3\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from pydantic_settings) (2.10.3)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from pydantic_settings) (0.21.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-core) (8.2.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.20 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (0.34.3)\n",
      "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (0.7.3)\n",
      "Requirement already satisfied: mmh3<6.0.0,>=4.1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (5.2.0)\n",
      "Requirement already satisfied: numpy>=1.26 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (1.26.4)\n",
      "Requirement already satisfied: onnxruntime!=1.20.0,>=1.17.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (1.22.1)\n",
      "Requirement already satisfied: pillow<12.0.0,>=10.3.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (10.3.0)\n",
      "Requirement already satisfied: py-rust-stemmers<0.2.0,>=0.1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (0.1.5)\n",
      "Requirement already satisfied: tokenizers<1.0,>=0.15 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (0.21.4)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from fastembed) (4.66.4)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from qdrant-client) (1.74.0)\n",
      "Requirement already satisfied: httpx>=0.20.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\n",
      "Requirement already satisfied: portalocker<4.0,>=2.7.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from qdrant-client) (3.2.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from qdrant-client) (6.31.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from qdrant-client) (2.2.2)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph) (0.6.2)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph) (0.2.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.20->fastembed) (2024.3.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed) (0.4.6)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed) (1.2.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.14.0)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from portalocker<4.0,>=2.7.0->qdrant-client) (305.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from pydantic>=2.7.0->pydantic_settings) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from pydantic>=2.7.0->pydantic_settings) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from sympy->onnxruntime!=1.20.0,>=1.17.0->fastembed) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime!=1.20.0,>=1.17.0->fastembed) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\sherl\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic_settings langchain langchain-core langchain-google-genai langchain-qdrant fastembed langchain-community qdrant-client langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81d0a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY: str\n",
    "    model_config = SettingsConfigDict(env_file=\".env\")\n",
    "\n",
    "env = Settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4026a7",
   "metadata": {},
   "source": [
    "# Create embeddings for doctor specialties/descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6c0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\", google_api_key=env.GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fdd0c5",
   "metadata": {},
   "source": [
    "# Create Vector Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad30c5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5eae0017-40dd-4961-869f-79d9e45d87f2', 'name': 'Adventia Emilia Krysna Sipi Seda, M.M., M.Psi., Psikolog', 'specialization_name': 'Psikologi', 'specialization_name_en': 'Psychology', 'sub_specialization_name': 'Psikolog', 'sub_specialization_name_en': 'Psychologist', 'hospital_name': 'Siloam Hospitals Yogyakarta'}\n"
     ]
    }
   ],
   "source": [
    "# load doctors_final.json data\n",
    "import json\n",
    "\n",
    "with open(\"doctors_final.json\", \"r\") as f:\n",
    "    doctor_data = json.load(f)\n",
    "\n",
    "print(doctor_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4aa1b",
   "metadata": {},
   "source": [
    "# Set up Qdrant vector DB in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73c091d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "import uuid\n",
    "\n",
    "\n",
    "collection_name = \"doctors\"\n",
    "dimension = 768\n",
    "distance = Distance.COSINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53c4fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'doctors' already exists.\n"
     ]
    }
   ],
   "source": [
    "if not client.collection_exists(collection_name=collection_name):\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=dimension, distance=distance),\n",
    "    )\n",
    "    print(f\"Collection '{collection_name}' created with dimension {dimension} and distance {distance}.\")\n",
    "else:\n",
    "    print(f\"Collection '{collection_name}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b1aa7",
   "metadata": {},
   "source": [
    "# doctors vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7399ca1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import json\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "# Batching and Rate Limit Settings\n",
    "BATCH_SIZE = 30  # Number of documents to embed in one API call and upsert\n",
    "RETRY_ATTEMPTS = 5\n",
    "INITIAL_RETRY_DELAY = 1  # Seconds for initial backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b046375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from qdrant_client.models import PointStruct\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_core.documents import Document # <--- THIS LINE IS ADDED/CORRECTED\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5e65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting embedding and upsert process for 1000 documents...\n",
      "Type of 'embeddings' before loop: <class 'langchain_google_genai.embeddings.GoogleGenerativeAIEmbeddings'>\n",
      "Embedding batch 1 (30 documents) with LangChain...\n",
      "Error embedding batch 1, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 1 (30 documents) with LangChain...\n",
      "Error embedding batch 1, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 1 (30 documents) with LangChain...\n",
      "Error embedding batch 1, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 1 (30 documents) with LangChain...\n",
      "Error embedding batch 1, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 1 (30 documents) with LangChain...\n",
      "Error embedding batch 1, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 1 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 2 (30 documents) with LangChain...\n",
      "Error embedding batch 2, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 2 (30 documents) with LangChain...\n",
      "Error embedding batch 2, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 2 (30 documents) with LangChain...\n",
      "Error embedding batch 2, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 2 (30 documents) with LangChain...\n",
      "Error embedding batch 2, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 2 (30 documents) with LangChain...\n",
      "Error embedding batch 2, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 2 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 3 (30 documents) with LangChain...\n",
      "Error embedding batch 3, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 3 (30 documents) with LangChain...\n",
      "Error embedding batch 3, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 3 (30 documents) with LangChain...\n",
      "Error embedding batch 3, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 3 (30 documents) with LangChain...\n",
      "Error embedding batch 3, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 3 (30 documents) with LangChain...\n",
      "Error embedding batch 3, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 3 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 4 (30 documents) with LangChain...\n",
      "Error embedding batch 4, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 4 (30 documents) with LangChain...\n",
      "Error embedding batch 4, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 4 (30 documents) with LangChain...\n",
      "Error embedding batch 4, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 4 (30 documents) with LangChain...\n",
      "Error embedding batch 4, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 4 (30 documents) with LangChain...\n",
      "Error embedding batch 4, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 4 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 5 (30 documents) with LangChain...\n",
      "Error embedding batch 5, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 5 (30 documents) with LangChain...\n",
      "Error embedding batch 5, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 5 (30 documents) with LangChain...\n",
      "Error embedding batch 5, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 5 (30 documents) with LangChain...\n",
      "Error embedding batch 5, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 5 (30 documents) with LangChain...\n",
      "Error embedding batch 5, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 5 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 6 (30 documents) with LangChain...\n",
      "Error embedding batch 6, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 6 (30 documents) with LangChain...\n",
      "Error embedding batch 6, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 6 (30 documents) with LangChain...\n",
      "Error embedding batch 6, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n",
      "Embedding batch 6 (30 documents) with LangChain...\n",
      "Error embedding batch 6, attempt 4/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 8.00 seconds before retrying...\n",
      "Embedding batch 6 (30 documents) with LangChain...\n",
      "Error embedding batch 6, attempt 5/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 16.00 seconds before retrying...\n",
      "Failed to embed batch 6 after 5 attempts. Skipping this batch.\n",
      "Embedding batch 7 (30 documents) with LangChain...\n",
      "Error embedding batch 7, attempt 1/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 1.00 seconds before retrying...\n",
      "Embedding batch 7 (30 documents) with LangChain...\n",
      "Error embedding batch 7, attempt 2/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 2.00 seconds before retrying...\n",
      "Embedding batch 7 (30 documents) with LangChain...\n",
      "Error embedding batch 7, attempt 3/5: Error embedding content: 429 Resource has been exhausted (e.g. check quota).\n",
      "Rate limit or resource error. Waiting for 4.00 seconds before retrying...\n"
     ]
    }
   ],
   "source": [
    "total_docs = len(doctor_data)\n",
    "print(f\"Starting embedding and upsert process for {total_docs} documents...\")\n",
    "print(f\"Type of 'embeddings' before loop: {type(embeddings)}\")\n",
    "# --- End debugging print statement ---\n",
    "\n",
    "for i in range(0, total_docs, BATCH_SIZE):\n",
    "    batch_data = doctor_data[i:i + BATCH_SIZE]\n",
    "\n",
    "    # Prepare texts and metadata for LangChain's embed_documents\n",
    "    langchain_docs = []\n",
    "    original_metadata_in_batch = [] # To store original doc for Qdrant payload\n",
    "\n",
    "    for doc in batch_data:\n",
    "        # The `description` field might be missing, so use .get with a default empty string\n",
    "        text_content = f\"Doctor: {doc.get('name', '')}, Specialty: {doc.get('specialization_name', '')}, Sub-Specialty: {doc.get('sub_specialization_name', '')}, Hospital: {doc.get('hospital_name', '')}, Description: {doc.get('description', '')}\"\n",
    "\n",
    "        # LangChain's Document class is useful here for structuring\n",
    "        langchain_docs.append(Document(page_content=text_content, metadata=doc))\n",
    "        original_metadata_in_batch.append(doc)\n",
    "\n",
    "    current_delay = INITIAL_RETRY_DELAY\n",
    "    embeddings_list = [] # Initialize embeddings_list here to ensure it's always defined\n",
    "\n",
    "    for attempt in range(RETRY_ATTEMPTS):\n",
    "        try:\n",
    "            # Use embed_documents for batching. This method handles internal API calls efficiently.\n",
    "            print(f\"Embedding batch {i//BATCH_SIZE + 1} ({len(langchain_docs)} documents) with LangChain...\")\n",
    "\n",
    "            # Pass only the page_content from the Document objects to embed_documents\n",
    "            embeddings_list = embeddings.embed_documents([doc.page_content for doc in langchain_docs])\n",
    "\n",
    "            break # Success, exit retry loop\n",
    "        except Exception as e:\n",
    "            print(f\"Error embedding batch {i//BATCH_SIZE + 1}, attempt {attempt + 1}/{RETRY_ATTEMPTS}: {e}\")\n",
    "            # LangChain's embeddings often handle retries internally, but if you still see errors\n",
    "            # (like ResourceExhausted), add an outer explicit delay for persistent rate limits.\n",
    "            if \"ResourceExhausted\" in str(e) or \"429\" in str(e) or \"quota\" in str(e).lower():\n",
    "                print(f\"Rate limit or resource error. Waiting for {current_delay:.2f} seconds before retrying...\")\n",
    "                time.sleep(current_delay)\n",
    "                current_delay *= 2 # Exponential backoff\n",
    "            else:\n",
    "                print(f\"Non-retryable error: {e}\")\n",
    "                break # Exit retry loop for other errors\n",
    "    else: # This 'else' block executes if the loop completes without a 'break' (i.e., all retries failed)\n",
    "        print(f\"Failed to embed batch {i//BATCH_SIZE + 1} after {RETRY_ATTEMPTS} attempts. Skipping this batch.\")\n",
    "        continue # Skip to the next batch\n",
    "\n",
    "    if not embeddings_list: # If no embeddings were generated due to errors (e.g., all retries failed)\n",
    "        print(f\"No embeddings generated for batch {i//BATCH_SIZE + 1}. Skipping upsert.\")\n",
    "        continue\n",
    "\n",
    "    # Prepare points for Qdrant upsert\n",
    "    points_to_upsert = []\n",
    "    for j, emb in enumerate(embeddings_list):\n",
    "        original_doc = original_metadata_in_batch[j]\n",
    "        text_content = langchain_docs[j].page_content # Get the exact text that was embedded\n",
    "\n",
    "        points_to_upsert.append(\n",
    "            PointStruct(\n",
    "                id=original_doc.get(\"id\") or str(uuid.uuid4()), # Use existing ID or generate new\n",
    "                vector=emb,\n",
    "                payload={\n",
    "                    \"page_content\": text_content,\n",
    "                    \"metadata\": original_doc # Store the full original document as metadata\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Upsert the batch to Qdrant\n",
    "    current_delay = INITIAL_RETRY_DELAY # Reset delay for upsert retries\n",
    "    for attempt in range(RETRY_ATTEMPTS):\n",
    "        try:\n",
    "            client.upsert(\n",
    "                collection_name=collection_name,\n",
    "                points=points_to_upsert,\n",
    "                wait=True \n",
    "            )\n",
    "            print(f\"Successfully upserted batch {i//BATCH_SIZE + 1} ({len(points_to_upsert)} documents) to Qdrant.\")\n",
    "            break \n",
    "        except Exception as e:\n",
    "            print(f\"Error upserting batch {i//BATCH_SIZE + 1} to Qdrant, attempt {attempt + 1}/{RETRY_ATTEMPTS}: {e}\")\n",
    "            print(f\"Waiting for {current_delay:.2f} seconds before retrying Qdrant upsert...\")\n",
    "            time.sleep(current_delay)\n",
    "            current_delay *= 2 # Exponential backoff\n",
    "    else:\n",
    "        print(f\"Failed to upsert batch {i//BATCH_SIZE + 1} to Qdrant after {RETRY_ATTEMPTS} attempts. Data for this batch might be missing.\")\n",
    "\n",
    "print(\"\\nEmbedding and upsert process completed.\")\n",
    "\n",
    "# Optional: Verify the count of points in the collection\n",
    "try:\n",
    "    collection_info = client.get_collection(collection_name=collection_name)\n",
    "    print(f\"\\nTotal points in Qdrant collection '{collection_name}': {collection_info.points_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not retrieve collection info: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "577c1584",
   "metadata": {},
   "outputs": [
    {
     "ename": "QdrantVectorStoreError",
     "evalue": "Existing Qdrant collection is configured for dense vectors with 3072 dimensions. Selected embeddings are 0-dimensional. If you want to recreate the collection, set `force_recreate` parameter to `True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQdrantVectorStoreError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# 3. Example usage\u001b[39;00m\n\u001b[0;32m     34\u001b[0m user_symptom \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI have chest pain and shortness of breath\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m recommendation \u001b[38;5;241m=\u001b[39m recommend_doctor_with_llm(user_symptom)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(recommendation)\n",
      "Cell \u001b[1;32mIn[26], line 15\u001b[0m, in \u001b[0;36mrecommend_doctor_with_llm\u001b[1;34m(symptom_query, top_k)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend_doctor_with_llm\u001b[39m(symptom_query, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Vector search for relevant doctors\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     vector_store \u001b[38;5;241m=\u001b[39m QdrantVectorStore(\n\u001b[0;32m     16\u001b[0m         client\u001b[38;5;241m=\u001b[39mclient,\n\u001b[0;32m     17\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m     18\u001b[0m         embedding\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     20\u001b[0m     retriever \u001b[38;5;241m=\u001b[39m vector_store\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[0;32m     21\u001b[0m     results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39minvoke(symptom_query, k\u001b[38;5;241m=\u001b[39mtop_k)\n",
      "File \u001b[1;32mc:\\Users\\sherl\\anaconda3\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:213\u001b[0m, in \u001b[0;36mQdrantVectorStore.__init__\u001b[1;34m(self, client, collection_name, embedding, retrieval_mode, vector_name, content_payload_key, metadata_payload_key, distance, sparse_embedding, sparse_vector_name, validate_embeddings, validate_collection_config)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embeddings(retrieval_mode, embedding, sparse_embedding)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_collection_config:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_collection_config(\n\u001b[0;32m    214\u001b[0m         client,\n\u001b[0;32m    215\u001b[0m         collection_name,\n\u001b[0;32m    216\u001b[0m         retrieval_mode,\n\u001b[0;32m    217\u001b[0m         vector_name,\n\u001b[0;32m    218\u001b[0m         sparse_vector_name,\n\u001b[0;32m    219\u001b[0m         distance,\n\u001b[0;32m    220\u001b[0m         embedding,\n\u001b[0;32m    221\u001b[0m     )\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m client\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollection_name \u001b[38;5;241m=\u001b[39m collection_name\n",
      "File \u001b[1;32mc:\\Users\\sherl\\anaconda3\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:1050\u001b[0m, in \u001b[0;36mQdrantVectorStore._validate_collection_config\u001b[1;34m(cls, client, collection_name, retrieval_mode, vector_name, sparse_vector_name, distance, embedding)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_collection_config\u001b[39m(\n\u001b[0;32m   1040\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type[QdrantVectorStore],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     embedding: Optional[Embeddings],\n\u001b[0;32m   1048\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retrieval_mode \u001b[38;5;241m==\u001b[39m RetrievalMode\u001b[38;5;241m.\u001b[39mDENSE:\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_collection_for_dense(\n\u001b[0;32m   1051\u001b[0m             client, collection_name, vector_name, distance, embedding\n\u001b[0;32m   1052\u001b[0m         )\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m retrieval_mode \u001b[38;5;241m==\u001b[39m RetrievalMode\u001b[38;5;241m.\u001b[39mSPARSE:\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_collection_for_sparse(\n\u001b[0;32m   1056\u001b[0m             client, collection_name, sparse_vector_name\n\u001b[0;32m   1057\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\sherl\\anaconda3\\Lib\\site-packages\\langchain_qdrant\\qdrant.py:1116\u001b[0m, in \u001b[0;36mQdrantVectorStore._validate_collection_for_dense\u001b[1;34m(cls, client, collection_name, vector_name, distance, dense_embeddings)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `embeddings` type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vector_config\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m!=\u001b[39m vector_size:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QdrantVectorStoreError(\n\u001b[0;32m   1117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExisting Qdrant collection is configured for dense vectors with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_config\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1119\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected embeddings are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-dimensional. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want to recreate the collection, set `force_recreate` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter to `True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1122\u001b[0m     )\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vector_config\u001b[38;5;241m.\u001b[39mdistance \u001b[38;5;241m!=\u001b[39m distance:\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m QdrantVectorStoreError(\n\u001b[0;32m   1126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExisting Qdrant collection is configured for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1127\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_config\u001b[38;5;241m.\u001b[39mdistance\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m similarity, but requested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter to `True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1132\u001b[0m     )\n",
      "\u001b[1;31mQdrantVectorStoreError\u001b[0m: Existing Qdrant collection is configured for dense vectors with 3072 dimensions. Selected embeddings are 0-dimensional. If you want to recreate the collection, set `force_recreate` parameter to `True`."
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 1. Set up the LLM\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=env.GOOGLE_API_KEY,\n",
    ")\n",
    "\n",
    "# 2. Define a function to recommend doctors using symptoms and LLM\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "def recommend_doctor_with_llm(symptom_query, top_k=5):\n",
    "    # Vector search for relevant doctors\n",
    "    vector_store = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "    retriever = vector_store.as_retriever()\n",
    "    results = retriever.invoke(symptom_query, k=top_k)\n",
    "    context = \"\\n\".join([r.page_content for r in results])\n",
    "\n",
    "    # Use LLM to generate a recommendation\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant that recommends doctors at Siloam Hospitals based on user symptoms and doctor specialties.\"),\n",
    "        (\"human\", \"User symptoms: {symptoms}\\nDoctor list:\\n{context}\\n\\nWhich doctor(s) would you recommend and why?\")\n",
    "    ])\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"symptoms\": symptom_query, \"context\": context})\n",
    "    return response.content\n",
    "\n",
    "# 3. Example usage\n",
    "user_symptom = \"I have chest pain and shortness of breath\"\n",
    "recommendation = recommend_doctor_with_llm(user_symptom)\n",
    "print(recommendation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
